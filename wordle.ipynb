{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254138ee-caf7-4a0f-8418-1976c0f9770f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3194 5-letter english words.\n"
     ]
    }
   ],
   "source": [
    "from english_words import english_words_lower_set\n",
    "\n",
    "words_5_letters = [ word for word in english_words_lower_set\n",
    "                   if (len(word) == 5) and (\"'\" not in word) and ('.' not in word) ]\n",
    "print(f'There are {len(words_5_letters)} 5-letter english words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735601ad-ce38-4788-9906-9e77928a6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate probability of each letter, and\n",
    "# calculate probability of each letter at position 0, 1, 2, 3, 4\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def get_letter_probabilities(dataset):\n",
    "    letters_overall_count = Counter()\n",
    "    position_letters_count = {}\n",
    "    for word in dataset:\n",
    "        for idx, letter in enumerate(word):\n",
    "            letters_overall_count.update(letter)\n",
    "            if idx in position_letters_count:\n",
    "                position_letters_count[idx].update(letter)\n",
    "            else:\n",
    "                position_letters_count[idx] = Counter(letter)\n",
    "                \n",
    "    return letters_overall_count, position_letters_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7143681-74c4-43d7-bea8-4d268d5b2d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weight of each word: probability of letter at position 'i' * probability of letter\n",
    "\n",
    "def get_weight_per_word(dataset, letters_overall_count, position_letters_count):\n",
    "    weights_per_word = []\n",
    "    for word in dataset:\n",
    "        weight = 0\n",
    "        for idx, letter in enumerate(word):\n",
    "            weight += (position_letters_count[idx][letter]/sum(position_letters_count[idx].values())) * (letters_overall_count[letter]/sum(letters_overall_count.values()))\n",
    "        weights_per_word.append( (weight, word) )\n",
    "    weights_per_word.sort(key = lambda tup: tup[0], reverse=True)\n",
    "    \n",
    "    return weights_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3cef51c-4964-408c-bbe2-481204dfac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify words which don't have repeating letters\n",
    "\n",
    "def get_words_unique_letters(dataset):\n",
    "    non_repeating_letters_words = []\n",
    "    for weight, word in dataset:\n",
    "        if len(set(word)) == 5:\n",
    "            non_repeating_letters_words.append( (weight, word) )\n",
    "        \n",
    "    return non_repeating_letters_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72236de-dfb3-4bb7-9ab8-dc6372f84865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify words combos (non-letter-repeating) and weights of such combos\n",
    "\n",
    "def get_words_combos_unique_letters(dataset):\n",
    "    unique_letters_words = []\n",
    "    idx = 0\n",
    "    while idx < len(dataset):\n",
    "        weight_combo = 0\n",
    "        words_combo = []\n",
    "        used_letters = set()\n",
    "        for weight, word in dataset[idx:]:\n",
    "            if set(word).isdisjoint(used_letters):\n",
    "                weight_combo += weight\n",
    "                words_combo.append(word)\n",
    "                used_letters.update(word)\n",
    "        unique_letters_words.append( [weight_combo, *words_combo] )\n",
    "        idx += 1\n",
    "    unique_letters_words.sort(key = lambda ls : ls[0], reverse=True)            \n",
    "        \n",
    "    return unique_letters_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c37373ec-34d8-4caf-bab4-246d129e9795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# letter is absent : remove words from dataset that contain the letter\n",
    "# letter is present, correct position: remove words from dataset with letter not in position\n",
    "# letter is present, wrong position: remove words from dataset without the letter\n",
    "\n",
    "def modify_dataset(dataset, absent_letters, present_letters_wrong_pos, present_letters_correct_pos):    \n",
    "    if absent_letters:\n",
    "        reduced_dataset = []\n",
    "        for word in dataset:\n",
    "            if set(word).isdisjoint(set(absent_letters)):\n",
    "                reduced_dataset.append(word)\n",
    "        dataset = reduced_dataset\n",
    "    \n",
    "    if present_letters_wrong_pos:\n",
    "        reduced_dataset = []\n",
    "        for word in dataset:\n",
    "            if not set(word).isdisjoint(set(present_letters_wrong_pos)):\n",
    "                reduced_dataset.append(word)\n",
    "        dataset = reduced_dataset\n",
    "        \n",
    "    if present_letters_correct_pos:\n",
    "        reduced_dataset = []\n",
    "        for word in dataset:\n",
    "            for letter, position in present_letters_correct_pos.items():\n",
    "                if word[position] != letter:\n",
    "                    match = False\n",
    "                    break\n",
    "                else:\n",
    "                    match = True\n",
    "            if match:\n",
    "                reduced_dataset.append(word)\n",
    "        dataset = reduced_dataset\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d077b7-b388-4c6c-9950-3d770ef9fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(dataset):\n",
    "    if len(dataset) == 1:\n",
    "        return dataset\n",
    "    else:\n",
    "        letters_overall_count, position_letters_count = get_letter_probabilities(dataset)\n",
    "        weights_per_word = get_weight_per_word(dataset, letters_overall_count, position_letters_count)\n",
    "        words_unique_letters = get_words_unique_letters(weights_per_word)\n",
    "        if not words_unique_letters:\n",
    "            print(f'No more words with non-repeating letters')\n",
    "            return weights_per_word\n",
    "        words_combos_max_weight = get_words_combos_unique_letters(words_unique_letters)\n",
    "\n",
    "        return words_combos_max_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e202345-2c6a-45d0-bec7-2d3a1b13205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2131 recommendations.\n",
      "Best guess: brine\n"
     ]
    }
   ],
   "source": [
    "initial_recommendations = get_recommendations(words_5_letters)\n",
    "print(f'There are {len(initial_recommendations)} recommendations.')\n",
    "print(f'Best guess: {initial_recommendations[0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85148435-00b9-4ab8-906e-190c9fd0e3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 232 recommendations.\n",
      "Best guess: salty\n"
     ]
    }
   ],
   "source": [
    "# guess1 = brine\n",
    "\n",
    "absent_letters = ['b', 'r', 'i', 'n', 'e']\n",
    "present_letters_wrong_pos = None\n",
    "present_letters_correct_pos = None\n",
    "reduced_dataset = modify_dataset(words_5_letters, absent_letters, present_letters_wrong_pos, present_letters_correct_pos)\n",
    "recommendations = get_recommendations(reduced_dataset)\n",
    "print(f'There are {len(recommendations)} recommendations.')\n",
    "print(f'Best guess: {recommendations[0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb7201d4-886b-4668-92a3-895771429490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 recommendations.\n",
      "Best guess: dumpy\n"
     ]
    }
   ],
   "source": [
    "# guess2 = salty\n",
    "\n",
    "absent_letters = ['s', 't', 'a', 'l']\n",
    "present_letters_wrong_pos = None\n",
    "present_letters_correct_pos = {'y': 4}\n",
    "reduced_dataset = modify_dataset(reduced_dataset, absent_letters, present_letters_wrong_pos, present_letters_correct_pos)\n",
    "recommendations = get_recommendations(reduced_dataset)\n",
    "print(f'There are {len(recommendations)} recommendations.')\n",
    "print(f'Best guess: {recommendations[0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6200cbca-d0d5-4228-9691-ea546ea86c63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more words with non-repeating letters\n",
      "There are 2 recommendations.\n",
      "Best guess: mummy\n"
     ]
    }
   ],
   "source": [
    "# guess3 = dumpy\n",
    "\n",
    "absent_letters = ['d', 'p']\n",
    "present_letters_wrong_pos = None\n",
    "present_letters_correct_pos = {'u': 1, 'm': 2, 'y': 4}\n",
    "reduced_dataset = modify_dataset(reduced_dataset, absent_letters, present_letters_wrong_pos, present_letters_correct_pos)\n",
    "recommendations = get_recommendations(reduced_dataset)\n",
    "print(f'There are {len(recommendations)} recommendations.')\n",
    "print(f'Best guess: {recommendations[0][1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
